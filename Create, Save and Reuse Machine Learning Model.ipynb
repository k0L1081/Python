{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple demo of how to create, save and reuse classification model. The ability to save and re-use a trained model is an important component in the productionizing of machine learning models.\n",
    "\n",
    "The model is created in **scikit-learn**.\n",
    "\n",
    "The model is saved and re-opened (serialized and deserialized) using **pickle**.\n",
    "\n",
    "The data set used for the demo is the **Iris Flower Dataset**: The data set consists of 3 different types of irises, namely Setosa, Versicolour, and Virginica. The rows are the observations. The columns are the features, namely: sepal length, sepal width, petal length and petal width."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from sklearn import svm, datasets\n",
    "import pickle \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris Flower Dataset is essentially a dictionary of various types, such as:\n",
    "\n",
    "** iris.data:** Numpy N-dimensional array containing 150 1x4 arrays of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.data))\n",
    "print(iris.data[:10])\n",
    "print(len(iris.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** iris.target:** Numpy N-dimensional array containing 150 target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.target))\n",
    "print(iris.target[:10])\n",
    "print(len(iris.target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**iris.feature_names:** List of feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n"
     ]
    }
   ],
   "source": [
    "print(type(iris.feature_names))\n",
    "print(iris.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the steps to build and serialize a simple SVM classication model using the scikit-learn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load iris observations.\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Set iris features.\n",
    "X = iris.data\n",
    "\n",
    "# Set iris target values.\n",
    "Y = iris.target\n",
    "\n",
    "# Train model and fit model on X & Y.\n",
    "# C=1.0: Optional penalty parameter of 1.0\n",
    "# kernel='poly': Specifies the 'poly' kernel type to be used in the algorithm.\n",
    "# degree=3: 3 degrees of the 'poly' kernel function\n",
    "model = svm.SVC(C=1.0, kernel='poly', degree=3).fit(X, Y)\n",
    "\n",
    "# Specify location to save model\n",
    "path = 'C:\\Temp\\model.pckl'\n",
    "\n",
    "# Save model.\n",
    "# Create new file named 'model.pckl'.\n",
    "# Open the file in 'wb' mode: Write Binary mode\n",
    "f = open(path, 'wb')\n",
    "\n",
    "# Serialize the model to the file.\n",
    "pickle.dump(model, f)\n",
    "\n",
    "# Close the file.\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0],\n",
       "       [0, 0]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open file and load saved model.\n",
    "f = open(path, 'rb')\n",
    "model = pickle.load(f)\n",
    "\n",
    "# Close file.\n",
    "f.close()\n",
    "\n",
    "# Create matrix of observations.\n",
    "observations = np.array(X).reshape(150,4)\n",
    "\n",
    "# Use model to perform predictions from observations.\n",
    "predictions = model.predict(observations)\n",
    "\n",
    "# Compare the observed target variable (Y) to the predictions.\n",
    "np.column_stack((Y, predictions))[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As demonstrated above, the target variable values match the prediction values. This is expected, since the model was trained on 100% of the data. Such an approach is fine for the purposes of this demo.\n",
    "\n",
    "In practice, you should **not** train your model on 100% of your data. Train on a subset (say 80%) of your observations; then evaluate your model, comparing the remaining 20%  of your observations to the associated predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
